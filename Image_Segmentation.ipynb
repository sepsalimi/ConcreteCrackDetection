{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Brainstation Capstone: Image Segmentation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### This notebook utilizes Meta's Segment Anything Model (SAM) to segment concrete structure to pass onto Crack_Detection model\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Before Starting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue May  9 13:33:47 2023       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 531.14                 Driver Version: 531.14       CUDA Version: 12.1     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                      TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf            Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce RTX 3060 L...  WDDM | 00000000:01:00.0  On |                  N/A |\n",
      "| N/A   55C    P8               19W /  N/A|    882MiB /  6144MiB |     90%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A      1964    C+G   ....0_x64__8she8kybcnzg4\\app\\Slack.exe    N/A      |\n",
      "|    0   N/A  N/A      2960    C+G   ...t.LockApp_cw5n1h2txyewy\\LockApp.exe    N/A      |\n",
      "|    0   N/A  N/A      8080    C+G   ...Programs\\Microsoft VS Code\\Code.exe    N/A      |\n",
      "|    0   N/A  N/A      9060    C+G   ...2txyewy\\StartMenuExperienceHost.exe    N/A      |\n",
      "|    0   N/A  N/A     10308    C+G   C:\\Windows\\explorer.exe                   N/A      |\n",
      "|    0   N/A  N/A     11160    C+G   ...siveControlPanel\\SystemSettings.exe    N/A      |\n",
      "|    0   N/A  N/A     13580    C+G   ...3890_x64__8wekyb3d8bbwe\\msteams.exe    N/A      |\n",
      "|    0   N/A  N/A     16360    C+G   ...nt.CBS_cw5n1h2txyewy\\SearchHost.exe    N/A      |\n",
      "|    0   N/A  N/A     18080    C+G   ...x64__qmba6cd70vzyy\\ArmouryCrate.exe    N/A      |\n",
      "|    0   N/A  N/A     22040    C+G   ...CBS_cw5n1h2txyewy\\TextInputHost.exe    N/A      |\n",
      "|    0   N/A  N/A     22260    C+G   ...ekyb3d8bbwe\\PhoneExperienceHost.exe    N/A      |\n",
      "|    0   N/A  N/A     23164    C+G   ...Software\\Current\\LogiOptionsMgr.exe    N/A      |\n",
      "|    0   N/A  N/A     23196    C+G   ...ns\\Software\\Current\\LogiOverlay.exe    N/A      |\n",
      "|    0   N/A  N/A     23348    C+G   ...cal\\Microsoft\\OneDrive\\OneDrive.exe    N/A      |\n",
      "|    0   N/A  N/A     25336    C+G   ...on\\113.0.1774.35\\msedgewebview2.exe    N/A      |\n",
      "|    0   N/A  N/A     27728    C+G   ...en Control\\bin\\OnScreen Control.exe    N/A      |\n",
      "|    0   N/A  N/A     29876    C+G   ...ejd91yc\\AdobeNotificationClient.exe    N/A      |\n",
      "|    0   N/A  N/A     31628    C+G   ...5n1h2txyewy\\ShellExperienceHost.exe    N/A      |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "# Check if GPU is available\n",
    "!nvidia-smi"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make it easier to manage datasets, images, and models, we create a <span style=\"background-color: black; color: white\">home</span> directory\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Home: \\\\sepehrnas\\Thick Volume\\CAREER\\SEPEHR\\EDUCATION\\Brainstation\\Data Science\\Deliverables\\Capstone\\segment_anything\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "HOME = os.getcwd()\n",
    "print(\"Home:\", HOME)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Meta's Segment Anything Model (SAM) and other dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WinError 2] The system cannot find the file specified: '(HOME)'\n",
      "\\\\sepehrnas\\Thick Volume\\CAREER\\SEPEHR\\EDUCATION\\Brainstation\\Data Science\\Deliverables\\Capstone\\segment_anything\n",
      "Package already installed\n"
     ]
    }
   ],
   "source": [
    "%cd (HOME)\n",
    "\n",
    "import sys\n",
    "import pkg_resources\n",
    "\n",
    "# Check if package exists\n",
    "if 'segment-anything' not in {pkg.key for pkg in pkg_resources.working_set}:\n",
    "    !{sys.executable} -m pip install git+https://github.com/facebookresearch/segment-anything.git\n",
    "else:\n",
    "    print('Package already installed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jupyter_bbox_widget is already installed\n",
      "roboflow is already installed\n",
      "supervision is already installed\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "\n",
    "# jupyter bbox widget - allows users to interactively draw bounding boxes around objects in an image\n",
    "if importlib.util.find_spec('jupyter_bbox_widget') is None:\n",
    "    # Install package\n",
    "    !pip install -q jupyter_bbox_widget\n",
    "else:\n",
    "   print('jupyter_bbox_widget is already installed')\n",
    "\n",
    "# roboflow - upload and preprocess own datasets, visualize and label images, and generate ML models\n",
    "if importlib.util.find_spec('roboflow') is None:\n",
    "    # Install package\n",
    "    !pip install -q roboflow\n",
    "else:\n",
    "   print('roboflow is already installed')    \n",
    "\n",
    "if importlib.util.find_spec('supervision') is None:\n",
    "    # Install package\n",
    "    !pip install -q supervision\n",
    "else:\n",
    "   print('supervision is already installed')    \n",
    "   \n",
    "# dataclass-json - allows user to convert between JSON and Python objects\n",
    "# try:\n",
    "#     import dataclass_json # if exists, will not download. Download takes a VERY long time\n",
    "# except ImportError:\n",
    "#     !pip install git+https://github.com/lidatong/dataclass-json.git"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download SAM weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\\\sepehrnas\\Thick Volume\\CAREER\\SEPEHR\\EDUCATION\\Brainstation\\Data Science\\Deliverables\\Capstone\\segment_anything\\models\n",
      "File already exists, no need to download.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Check if directory exists, create if necessary\n",
    "if not os.path.exists(f\"{HOME}/models\"):\n",
    "    os.mkdir(f\"{HOME}/models\")\n",
    "\n",
    "# Change directory to models folder\n",
    "%cd {HOME}/models\n",
    "\n",
    "# Check if file already exists\n",
    "if not os.path.exists(\"sam_vit_h_4b8939.pth\"):\n",
    "    # Download file\n",
    "    !wget -q https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth\n",
    "else:\n",
    "    print(\"File already exists, no need to download.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\\\sepehrnas\\Thick Volume\\CAREER\\SEPEHR\\EDUCATION\\Brainstation\\Data Science\\Deliverables\\Capstone\\segment_anything\\models\\sam_vit_h_4b8939.pth ; exist: \n",
      " True\n"
     ]
    }
   ],
   "source": [
    "# Sanity check: confirming file exists\n",
    "\n",
    "CHECKPOINT_PATH = os.path.join(HOME, 'models', 'sam_vit_h_4b8939.pth')\n",
    "print(CHECKPOINT_PATH, \"; exist: \\n\", os.path.isfile(CHECKPOINT_PATH))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\\\sepehrnas\\Thick Volume\\CAREER\\SEPEHR\\EDUCATION\\Brainstation\\Data Science\\Deliverables\\Capstone\\segment_anything\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The syntax of the command is incorrect.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\\\sepehrnas\\Thick Volume\\CAREER\\SEPEHR\\EDUCATION\\Brainstation\\Data Science\\Deliverables\\Capstone\\segment_anything\\data\n"
     ]
    }
   ],
   "source": [
    "# os.chdir() if .py file\n",
    "%cd {HOME}\n",
    "\n",
    "# !mkdir = os.mkdir() if.py file\n",
    "!mkdir {HOME}/data\n",
    "\n",
    "%cd {HOME}/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File path is: \n",
      "\\\\sepehrnas\\Thick Volume\\CAREER\\SEPEHR\\EDUCATION\\Brainstation\\Data Science\\Deliverables\\Capstone\\segment_anything\\Data\\Drone Shots\\image001.jpg\n"
     ]
    }
   ],
   "source": [
    "# ensure file type is correct, for example .jpg vs .jpeg\n",
    "\n",
    "IMAGE_NAME = 'image001.jpg'\n",
    "IMAGE_PATH = os.path.join(HOME, \"Data\", 'Drone Shots', IMAGE_NAME)\n",
    "print(f'File path is: \\n{IMAGE_PATH}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Model & Image(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import supervision as sv\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cuda Status: True\n"
     ]
    }
   ],
   "source": [
    "# DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else \"cpu\")\n",
    "DEVICE = \"cpu\"\n",
    "MODEL_TYPE = 'vit_h'\n",
    "\n",
    "cuda_status = torch.cuda.is_available() # check if CUDA is available\n",
    "print(f'Cuda Status: {cuda_status}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from Meta's segment_anything:\n",
    "\n",
    "# model SamPredictor\n",
    "from segment_anything import SamPredictor\n",
    "\n",
    "# for selected mask generation\n",
    "from segment_anything import sam_model_registry\n",
    "\n",
    "# for automatic mask generation\n",
    "from segment_anything import SamAutomaticMaskGenerator\n",
    "\n",
    "# Model type parameter, location, and cpu/gpu selection\n",
    "sam = sam_model_registry[MODEL_TYPE](checkpoint = CHECKPOINT_PATH).to(device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read image\n",
    "image_bgr = cv2.imread(IMAGE_PATH)\n",
    "\n",
    "# Resize image to 1920x1080\n",
    "image_bgr = cv2.resize(image_bgr, (1920,1080))\n",
    "\n",
    "#convert from BGR to RGB\n",
    "image_rgb = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB) \n",
    "\n",
    "# copy for non destructive\n",
    "img = image_bgr.copy()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Segmenation with Mouse Clicks"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SamPredictor class provides an easy interface for user to set an image using the set_image method. Input is both point (and if needed can be tweaked to have box) prompts"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Instructions: \n",
    " 1) Once image is loaded, select multiple points with left click for foreground to be included in mask\n",
    " 2) And select background points with right click to be excluded from mask\n",
    " 3) Once desired points are selected, press any keyboard key to continue\n",
    " 4) Wait until mask is generated\n",
    " 5) Once mask is generated, press any keyboard key to finish. If mask is acceptable, continue to next cell to save masked image, otherwise redo this cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Foreground Coordinates Saved: (128, 410)\n",
      "Foreground Coordinates Appended: (136, 474)\n",
      "Foreground Coordinates Appended: (153, 435)\n",
      "Foreground Coordinates Appended: (98, 584)\n",
      "Foreground Coordinates Appended: (61, 652)\n",
      "Foreground Coordinates Appended: (23, 513)\n",
      "Foreground Coordinates Appended: (18, 407)\n",
      "Foreground Coordinates Appended: (755, 174)\n",
      "Foreground Coordinates Appended: (469, 108)\n",
      "Foreground Coordinates Appended: (264, 164)\n",
      "Foreground Coordinates Appended: (204, 485)\n",
      "Foreground Coordinates Appended: (66, 776)\n",
      "Foreground Coordinates Appended: (293, 880)\n",
      "Foreground Coordinates Appended: (688, 887)\n",
      "Foreground Coordinates Appended: (835, 824)\n",
      "Foreground Coordinates Appended: (743, 502)\n",
      "Foreground Coordinates Appended: (470, 500)\n",
      "Foreground Coordinates Appended: (306, 942)\n",
      "Foreground Coordinates Appended: (97, 956)\n",
      "Foreground Coordinates Appended: (775, 985)\n",
      "Foreground Coordinates Appended: (989, 905)\n",
      "Foreground Coordinates Appended: (939, 751)\n",
      "Foreground Coordinates Appended: (919, 570)\n",
      "Foreground Coordinates Appended: (841, 523)\n",
      "Foreground Coordinates Appended: (856, 663)\n",
      "Foreground Coordinates Appended: (1303, 883)\n",
      "Foreground Coordinates Appended: (1352, 570)\n",
      "Foreground Coordinates Appended: (1342, 407)\n",
      "Foreground Coordinates Appended: (1574, 357)\n",
      "Foreground Coordinates Appended: (1599, 572)\n",
      "Foreground Coordinates Appended: (1623, 841)\n",
      "Foreground Coordinates Appended: (1868, 837)\n",
      "Foreground Coordinates Appended: (1783, 657)\n",
      "Foreground Coordinates Appended: (1716, 459)\n",
      "Foreground Coordinates Appended: (1685, 346)\n",
      "Foreground Coordinates Appended: (1879, 978)\n",
      "Foreground Coordinates Appended: (1520, 983)\n",
      "Foreground Coordinates Appended: (1302, 987)\n",
      "Background Coordinates Appended: (1712, 1032)\n",
      "Background Coordinates Appended: (823, 1046)\n",
      "Background Coordinates Appended: (186, 1031)\n",
      "Background Coordinates Appended: (1135, 538)\n",
      "Background Coordinates Appended: (1858, 98)\n",
      "\n",
      "Please wait... Generating Masks\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Function to record user mouse click coordinates\n",
    "def onMouse(event, x, y, flags, param):\n",
    "   \n",
    "   #make input_label and input_coordinates global to access after function callback\n",
    "   global input_label\n",
    "   global input_coordinates\n",
    "        \n",
    "   # foreground selection with left click     \n",
    "   if event == cv2.EVENT_LBUTTONDOWN:\n",
    "   \n",
    "      # this is a foreground selection, save new coordinates\n",
    "      new_label = np.array([1])\n",
    "      \n",
    "      # new coordinates saved   \n",
    "      new_coordinates = np.array([[x, y]]) \n",
    "      \n",
    "      # if no coordinates have been selected, save coordinates\n",
    "      if(len(input_coordinates)==0):\n",
    "         input_label = new_label\n",
    "         input_coordinates = new_coordinates\n",
    "         print(f'Foreground Coordinates Saved: {x,y}')\n",
    "      \n",
    "      # if coordinates have already been selected, append new coordinates to a new row\n",
    "      else:\n",
    "         input_label = np.append(input_label, new_label, axis = 0)\n",
    "         input_coordinates = np.append(input_coordinates,new_coordinates, axis = 0)\n",
    "         print(f'Foreground Coordinates Appended: {x,y}')\n",
    "         \n",
    "   # background selection with right click\n",
    "   elif event == cv2.EVENT_RBUTTONDOWN:\n",
    "      \n",
    "      # this is a background selection\n",
    "      new_label = np.array([0])\n",
    "      \n",
    "      # new coordinates saved   \n",
    "      new_coordinates = np.array([[x, y]]) \n",
    "      \n",
    "      # if no coordinates have been selected, save coordinates\n",
    "      if(len(input_coordinates)==0):\n",
    "         input_label = new_label\n",
    "         input_coordinates = new_coordinates\n",
    "         print(f'Background Coordinates Saved: {x,y}')\n",
    "      \n",
    "      # if coordinates have already been selected, append new coordinates to a new row\n",
    "      else:\n",
    "         input_label = np.append(input_label, new_label, axis = 0)\n",
    "         input_coordinates = np.append(input_coordinates,new_coordinates, axis = 0 )\n",
    "         print(f'Background Coordinates Appended: {x,y}')\n",
    "         \n",
    "# create a named window, always on top, and display the image\n",
    "cv2.namedWindow('Image', cv2.WINDOW_NORMAL)\n",
    "cv2.setWindowProperty('Image', cv2.WND_PROP_TOPMOST, 1)\n",
    "cv2.imshow('Image', image_rgb)\n",
    "\n",
    "# Initialize coordinate array for mouse callback, and input label, then use onMouse\n",
    "input_coordinates = []\n",
    "input_label = []\n",
    "cv2.setMouseCallback('Image', onMouse) \n",
    "\n",
    "# press a button to exit\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyWindow('Image')\n",
    "print('\\nPlease wait... Generating Masks\\n')\n",
    "\n",
    "# Save input coordinates and labels into a numpy array\n",
    "input_coordinates = np.array(input_coordinates)\n",
    "input_label = np.array(input_label)\n",
    "\n",
    "# Select mask predictor model\n",
    "mask_predictor = SamPredictor(sam)\n",
    "\n",
    "# set image for mask predictor\n",
    "mask_predictor.set_image(image_rgb)\n",
    "\n",
    "# Use the mask predictor to generate mask\n",
    "masks, scores, logits = mask_predictor.predict(\n",
    "   point_coords=input_coordinates,\n",
    "   point_labels=input_label,\n",
    "   multimask_output=False,\n",
    ")\n",
    "\n",
    "# loop in case multimask output is set to True. However, output is only last mask, needs modification\n",
    "for mask in masks:\n",
    "   # Convert mask to binary\n",
    "   mask = np.where(masks == True, 0, 255).astype('uint8')\n",
    "\n",
    "   # resize mask to original image size\n",
    "   mask = np.reshape(mask,(img.shape[0], img.shape[1]))\n",
    "      \n",
    "   # Mask applied to R, G, and B Channels\n",
    "   mask = np.dstack([np.array(mask, dtype=np.uint8)]*3)\n",
    "\n",
    "   # Mask weighted at 100%, and image at 0% to get black and white\n",
    "   mask = cv2.addWeighted(mask,1,img,0,0)\n",
    "\n",
    "   # Window Name\n",
    "   window_name = 'Masked Image'\n",
    "\n",
    "   # create a named window for the image display\n",
    "   cv2.namedWindow(window_name, cv2.WINDOW_NORMAL)\n",
    "\n",
    "   # Set the windows to be always on top\n",
    "   cv2.setWindowProperty(window_name, cv2.WND_PROP_TOPMOST, 1)\n",
    "\n",
    "   # Display the image\n",
    "   cv2.imshow(window_name, mask)\n",
    "\n",
    "   # Press button to exit\n",
    "   cv2.waitKey(0)\n",
    "   cv2.destroyWindow(window_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n",
      "Mask saved to: \\\\sepehrnas\\Thick Volume\\CAREER\\SEPEHR\\EDUCATION\\Brainstation\\Data Science\\Deliverables\\Capstone\\segment_anything\\Drone Shots/Supervised Masks\\image001_mask.png\n"
     ]
    }
   ],
   "source": [
    "# Create folder if it doesn't exist\n",
    "if not os.path.exists('Drone Shots/Supervised Masks'):\n",
    "    os.makedirs('Drone Shots/Supervised Masks')\n",
    "\n",
    "# Save the mask with the same name as the original image\n",
    "IMAGE_NAME_WITHOUT_EXTENSION = os.path.splitext(IMAGE_NAME)[0]\n",
    "mask_name = IMAGE_NAME_WITHOUT_EXTENSION + \"_mask.png\"\n",
    "mask_path = os.path.join(\"Drone Shots/Supervised Masks\", mask_name)\n",
    "cv2.imwrite(mask_path, mask)\n",
    "\n",
    "# To be used in next python script\n",
    "mask_np_name = IMAGE_NAME_WITHOUT_EXTENSION + \"_mask.npy\"\n",
    "mask_np_path = os.path.join(\"Drone Shots/Supervised Masks\", mask_np_name)\n",
    "np.save(mask_np_path, mask)\n",
    "\n",
    "print(f'Success!\\nMask saved to: {os.path.join(HOME, mask_path)}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automated Mask Generation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uses a SAM model to the SamAutomaticGenerator class. Path is based on 'CHECKPOINT_PATH'. Running on CUDA is recommended."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_generator = SamAutomaticMaskGenerator(sam)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate masks with SAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sam_result = mask_generator.generate(image_rgb)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output Format"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SamAutomaticGenerator returns a list of masks, where each mask is a dict containing various information about the mask:\n",
    "\n",
    "- Segmentation - [np.ndarray] - the mask with (W,H) shape, and bool type\n",
    "\n",
    "- area - [int] - the area of the mask in pixels\n",
    "\n",
    "- bbox - [List[int]] - the boundary box of the mask in xywh format\n",
    "\n",
    "- predicted_iou - [float] - the models' own prediction for the quality of the mask\n",
    "\n",
    "- point_coords - [List[List[float]]] - the sampled input point that generated this mask\n",
    "\n",
    "- stability_score - [float] - an additional measure of mask quality\n",
    "\n",
    "- crop_box - List[int] - the crop of the image used to generate this mask in xywh format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sam_result[0].keys()) # first mask on the list"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results Visualization with Supervision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_annotator = sv.MaskAnnotator()\n",
    "\n",
    "detections = sv.Detections.from_sam(sam_result=sam_result)\n",
    "\n",
    "annotated_image = mask_annotator.annotate(scene =image_bgr.copy(), detections = detections)\n",
    "\n",
    "sv.plot_images_grid(\n",
    "   images = [image_bgr, annotated_image],\n",
    "   grid_size = (1,2),\n",
    "   titles = ['Source Image', 'Segmented Image']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masks = [\n",
    "   mask['segmentation']\n",
    "   for mask\n",
    "   in sorted(sam_result, key = lambda x: x['area'], reverse = True)\n",
    "]\n",
    "\n",
    "num_masks = len(masks)\n",
    "rows = int(num_masks / 8) + (1 if num_masks % 8 > 0 else 0)  # calculate number of rows needed\n",
    "grid_size = (8, rows)\n",
    "size = (16, 16)\n",
    "\n",
    "sv.plot_images_grid(images=masks, grid_size=grid_size, size=size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# which mask chosen\n",
    "chosen_mask = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = masks[chosen_mask]\n",
    "\n",
    "# Invert the mask and convert it to uint8\n",
    "mask = np.where(mask, 0, 255).astype('uint8')\n",
    "\n",
    "# Create folder if it doesn't exist\n",
    "if not os.path.exists('Drone Shots/Automatic Masks'):\n",
    "    os.makedirs('Drone Shots/Automatic Masks')\n",
    "\n",
    "# Save the mask with the same name as the original image\n",
    "IMAGE_NAME_WITHOUT_EXTENSION = os.path.splitext(IMAGE_NAME)[0]\n",
    "mask_name = IMAGE_NAME_WITHOUT_EXTENSION + \"_mask.png\"\n",
    "mask_path = os.path.join(\"Drone Shots/Automatic Masks\", mask_name)\n",
    "cv2.imwrite(mask_path, mask)\n",
    "\n",
    "# Display the segmented image\n",
    "mask_annotator = sv.MaskAnnotator()\n",
    "detections = sv.Detections.from_sam(sam_result=sam_result)\n",
    "annotated_image = mask_annotator.annotate(scene=image_bgr.copy(), detections=detections)\n",
    "sv.plot_images_grid(images=[image_bgr, annotated_image], grid_size=(1,2), titles=['Source Image', 'Segmented Image'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
